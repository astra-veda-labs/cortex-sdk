# ğŸ›ï¸ API Controls Guide

## âœ… **NEW! Real-Time API Toggle Controls**

You now have **full control** over the chatbot's behavior through toggle switches in the UI!

---

## ğŸ¯ **Three API Controls:**

### 1. ğŸ§  **Memory Context (Semantic Search)**
**What it does:** Controls whether the bot uses past conversation context
- âœ… **ON**: Bot remembers and uses past messages for better responses
- âŒ **OFF**: Bot ignores past context, treats each message independently

**Example:**
```
Memory Context ON:  "What's my name?" â†’ "Your name is Alice" (remembers)
Memory Context OFF: "What's my name?" â†’ "I don't know your name" (forgets)
```

---

### 2. âš¡ **Answer Caching (Instant Responses)**
**What it does:** Controls whether identical questions get instant cached answers
- âœ… **ON**: Identical questions get instant responses (no LLM call)
- âŒ **OFF**: Every question goes to LLM (slower but always fresh)

**Example:**
```
Answer Cache ON:  "Price of Honda?" â†’ Instant cached answer âš¡
Answer Cache OFF: "Price of Honda?" â†’ LLM generates new answer (5-8s)
```

---

### 3. ğŸ’­ **Fresh LLM (Always Generate)**
**What it does:** Controls whether the LLM generates responses
- âœ… **ON**: LLM generates intelligent responses
- âŒ **OFF**: Returns simple fallback message

**Example:**
```
Fresh LLM ON:  "How are you?" â†’ "I'm doing well, thank you for asking!"
Fresh LLM OFF: "How are you?" â†’ "I'm currently in a limited mode..."
```

---

## ğŸ§ª **Testing Scenarios:**

### Scenario 1: **Memory Context Testing**
```
1. Turn ON Memory Context
2. Say: "My name is Alice"
3. Ask: "What's my name?"
4. Result: "Alice" (remembers!)

5. Turn OFF Memory Context  
6. Ask: "What's my name?"
7. Result: "I don't know" (forgets!)
```

### Scenario 2: **Answer Caching Testing**
```
1. Turn ON Answer Caching
2. Ask: "Price of Honda?"
3. Wait 8 seconds for LLM response
4. Ask SAME: "Price of Honda?"
5. Result: Instant cached answer! âš¡

6. Turn OFF Answer Caching
7. Ask: "Price of Honda?" (again)
8. Result: LLM generates new response (5-8s)
```

### Scenario 3: **Fresh LLM Testing**
```
1. Turn OFF Fresh LLM
2. Ask: "How are you?"
3. Result: "I'm currently in a limited mode..."

4. Turn ON Fresh LLM
5. Ask: "How are you?"
6. Result: Full intelligent response!
```

---

## ğŸ”§ **How It Works:**

### **Frontend (UI):**
- Toggle switches send `api_settings` with each message
- Real-time control without page refresh
- Visual feedback with toggle states

### **Backend (API):**
- Receives `api_settings` in `/chat` endpoint
- Passes settings to `generate_response()` method
- Respects each toggle independently

### **Chatbot Logic:**
- **Memory Context**: Controls `use_semantic_context` parameter
- **Answer Caching**: Controls `use_answer_cache` parameter  
- **Fresh LLM**: Controls `use_fresh_llm` parameter

---

## ğŸ“Š **Response Indicators:**

The UI shows **exactly** what happened:

| Toggle State | Response Badge | What It Means |
|--------------|----------------|---------------|
| ğŸ§  **Memory ON** | ğŸ§  LLM response using X past messages as context | LLM + Memory |
| ğŸ§  **Memory OFF** | ğŸ’­ Fresh LLM response (no past context found) | LLM only |
| âš¡ **Cache ON** | âš¡ Cached answer (X% similar) - Instant response! | Memory only |
| âš¡ **Cache OFF** | ğŸ§ /ğŸ’­ LLM response | LLM always |
| ğŸ’­ **LLM ON** | ğŸ§ /ğŸ’­/âš¡ Normal response | Full functionality |
| ğŸ’­ **LLM OFF** | Limited mode message | No LLM |

---

## ğŸ¯ **Use Cases:**

### **Development & Testing:**
- **Test Memory**: Turn OFF memory, see if responses change
- **Test Caching**: Turn OFF cache, see if responses are always fresh
- **Test LLM**: Turn OFF LLM, see fallback behavior

### **Performance Testing:**
- **Speed Test**: Turn ON cache, measure instant responses
- **Memory Test**: Turn OFF memory, test without context
- **LLM Test**: Turn OFF LLM, test fallback mode

### **Debugging:**
- **Isolate Issues**: Turn OFF specific features to find problems
- **Compare Modes**: See difference between memory vs no-memory
- **Cache Testing**: Verify cached vs fresh responses

---

## ğŸš€ **Quick Test:**

**Refresh your browser** at `http://localhost:5001`

**Try this sequence:**
1. **Turn OFF Memory Context**
2. Ask: "What's my name?"
3. Should show: ğŸ’­ **Fresh LLM response (no past context found)**

4. **Turn ON Memory Context**  
5. Say: "My name is Alice"
6. Ask: "What's my name?"
7. Should show: ğŸ§  **LLM response using 1 past message as context**

**Perfect!** You now have **full control** over the chatbot's behavior! ğŸ¯âœ…
